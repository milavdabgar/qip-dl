{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jaN8oMJde8LB"
      },
      "source": [
        "# **Data Preprocessing Tools**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRvQnvV2fByw"
      },
      "source": [
        "# Importing the libraries\n",
        "\n",
        "\n",
        "*   numpy\n",
        "*   matplotlib.pyplot\n",
        "*   pandas\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Importing the libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpZYOYxXfUBp"
      },
      "source": [
        "# Importing following dataset\n",
        "\n",
        "*   Data.csv (explore... read_csv() command)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset shape: (10, 4)\n",
            "\n",
            "First 5 rows:\n",
            "   Country   Age   Salary Purchased\n",
            "0   France  44.0  72000.0        No\n",
            "1    Spain  27.0  48000.0       Yes\n",
            "2  Germany  30.0  54000.0        No\n",
            "3    Spain  38.0  61000.0        No\n",
            "4  Germany  40.0      NaN       Yes\n",
            "\n",
            "Dataset info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10 entries, 0 to 9\n",
            "Data columns (total 4 columns):\n",
            " #   Column     Non-Null Count  Dtype  \n",
            "---  ------     --------------  -----  \n",
            " 0   Country    10 non-null     object \n",
            " 1   Age        9 non-null      float64\n",
            " 2   Salary     9 non-null      float64\n",
            " 3   Purchased  10 non-null     object \n",
            "dtypes: float64(2), object(2)\n",
            "memory usage: 452.0+ bytes\n",
            "None\n",
            "\n",
            "Dataset description:\n",
            "             Age        Salary\n",
            "count   9.000000      9.000000\n",
            "mean   38.777778  63777.777778\n",
            "std     7.693793  12265.579662\n",
            "min    27.000000  48000.000000\n",
            "25%    35.000000  54000.000000\n",
            "50%    38.000000  61000.000000\n",
            "75%    44.000000  72000.000000\n",
            "max    50.000000  83000.000000\n"
          ]
        }
      ],
      "source": [
        "# Importing the dataset\n",
        "dataset = pd.read_csv('Data.csv')\n",
        "print(\"Dataset shape:\", dataset.shape)\n",
        "print(\"\\nFirst 5 rows:\")\n",
        "print(dataset.head())\n",
        "print(\"\\nDataset info:\")\n",
        "print(dataset.info())\n",
        "print(\"\\nDataset description:\")\n",
        "print(dataset.describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvKiPcunffa3"
      },
      "source": [
        "# Extract Independent variable and dependent variable\n",
        "\n",
        "\n",
        "*   Explore iloc with numpy values\n",
        "*   Print and see the variables\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Independent variables (X):\n",
            "[['France' 44.0 72000.0]\n",
            " ['Spain' 27.0 48000.0]\n",
            " ['Germany' 30.0 54000.0]\n",
            " ['Spain' 38.0 61000.0]\n",
            " ['Germany' 40.0 nan]\n",
            " ['France' 35.0 58000.0]\n",
            " ['Spain' nan 52000.0]\n",
            " ['France' 48.0 79000.0]\n",
            " ['Germany' 50.0 83000.0]\n",
            " ['France' 37.0 67000.0]]\n",
            "\n",
            "Shape of X: (10, 3)\n",
            "\n",
            "Dependent variable (y):\n",
            "['No' 'Yes' 'No' 'No' 'Yes' 'Yes' 'No' 'Yes' 'No' 'Yes']\n",
            "\n",
            "Shape of y: (10,)\n"
          ]
        }
      ],
      "source": [
        "# Extract Independent variable and dependent variable\n",
        "# Independent variables (features): Country, Age, Salary (all columns except last)\n",
        "X = dataset.iloc[:, :-1].values\n",
        "# Dependent variable (target): Purchased (last column)\n",
        "y = dataset.iloc[:, -1].values\n",
        "\n",
        "print(\"Independent variables (X):\")\n",
        "print(X)\n",
        "print(\"\\nShape of X:\", X.shape)\n",
        "print(\"\\nDependent variable (y):\")\n",
        "print(y)\n",
        "print(\"\\nShape of y:\", y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHYWpTT2gCsQ"
      },
      "source": [
        "# Taking care of missing data\n",
        "\n",
        "\n",
        "*   Explore SimpleImputer command\n",
        "*   NaN must be replaced with \"mean\" strategy\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data after handling missing values:\n",
            "[['France' 44.0 72000.0]\n",
            " ['Spain' 27.0 48000.0]\n",
            " ['Germany' 30.0 54000.0]\n",
            " ['Spain' 38.0 61000.0]\n",
            " ['Germany' 40.0 63777.77777777778]\n",
            " ['France' 35.0 58000.0]\n",
            " ['Spain' 38.77777777777778 52000.0]\n",
            " ['France' 48.0 79000.0]\n",
            " ['Germany' 50.0 83000.0]\n",
            " ['France' 37.0 67000.0]]\n",
            "\n",
            "Checking for any remaining missing values:\n",
            "Missing values in X: 0\n"
          ]
        }
      ],
      "source": [
        "# Taking care of missing data\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Create imputer object with mean strategy for numerical columns\n",
        "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "\n",
        "# Apply imputer to numerical columns (Age and Salary - columns 1 and 2)\n",
        "imputer = imputer.fit(X[:, 1:3])\n",
        "X[:, 1:3] = imputer.transform(X[:, 1:3])\n",
        "\n",
        "print(\"Data after handling missing values:\")\n",
        "print(X)\n",
        "print(\"\\nChecking for any remaining missing values:\")\n",
        "print(\"Missing values in X:\", pd.DataFrame(X).isnull().sum().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkTB0IuAguLQ"
      },
      "source": [
        "# Encoding categorical data\n",
        "\n",
        "*   Encoding the Independent Variable--explore ColumnTransformer function and OneHotEncoder function\n",
        "*   Encoding the Dependent Variable--explore LabelEncoder function\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Independent variables after encoding:\n",
            "[[1.0 0.0 0.0 44.0 72000.0]\n",
            " [0.0 0.0 1.0 27.0 48000.0]\n",
            " [0.0 1.0 0.0 30.0 54000.0]\n",
            " [0.0 0.0 1.0 38.0 61000.0]\n",
            " [0.0 1.0 0.0 40.0 63777.77777777778]\n",
            " [1.0 0.0 0.0 35.0 58000.0]\n",
            " [0.0 0.0 1.0 38.77777777777778 52000.0]\n",
            " [1.0 0.0 0.0 48.0 79000.0]\n",
            " [0.0 1.0 0.0 50.0 83000.0]\n",
            " [1.0 0.0 0.0 37.0 67000.0]]\n",
            "\n",
            "Shape of X after encoding: (10, 5)\n",
            "\n",
            "Dependent variable after encoding:\n",
            "[0 1 0 0 1 1 0 1 0 1]\n",
            "\n",
            "Label mapping:\n",
            "Classes: ['No' 'Yes']\n",
            "Yes -> 1, No -> 0\n"
          ]
        }
      ],
      "source": [
        "# Encoding categorical data\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
        "\n",
        "# Encoding the Independent Variable (Country column - index 0)\n",
        "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0])], remainder='passthrough')\n",
        "X = np.array(ct.fit_transform(X))\n",
        "\n",
        "print(\"Independent variables after encoding:\")\n",
        "print(X)\n",
        "print(\"\\nShape of X after encoding:\", X.shape)\n",
        "\n",
        "# Encoding the Dependent Variable (Purchased: Yes/No -> 1/0)\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)\n",
        "\n",
        "print(\"\\nDependent variable after encoding:\")\n",
        "print(y)\n",
        "print(\"\\nLabel mapping:\")\n",
        "print(\"Classes:\", le.classes_)\n",
        "print(\"Yes -> 1, No -> 0\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUnFk3f4hbJ4"
      },
      "source": [
        "# Feature Scaling\n",
        "\n",
        "*   Explore StandardScaler\n",
        "*   Print data for training and testing\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set shape:\n",
            "X_train: (8, 5)\n",
            "y_train: (8,)\n",
            "\n",
            "Test set shape:\n",
            "X_test: (2, 5)\n",
            "y_test: (2,)\n"
          ]
        }
      ],
      "source": [
        "# Splitting the dataset into Training set and Test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
        "\n",
        "print(\"Training set shape:\")\n",
        "print(\"X_train:\", X_train.shape)\n",
        "print(\"y_train:\", y_train.shape)\n",
        "print(\"\\nTest set shape:\")\n",
        "print(\"X_test:\", X_test.shape)\n",
        "print(\"y_test:\", y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set after feature scaling:\n",
            "[[0.0 0.0 1.0 -0.19159184384578545 -1.0781259408412425]\n",
            " [0.0 1.0 0.0 -0.014117293757057777 -0.07013167641635372]\n",
            " [1.0 0.0 0.0 0.566708506533324 0.633562432710455]\n",
            " [0.0 0.0 1.0 -0.30453019390224867 -0.30786617274297867]\n",
            " [0.0 0.0 1.0 -1.9018011447007988 -1.420463615551582]\n",
            " [1.0 0.0 0.0 1.1475343068237058 1.232653363453549]\n",
            " [0.0 1.0 0.0 1.4379472069688968 1.5749910381638885]\n",
            " [1.0 0.0 0.0 -0.7401495441200351 -0.5646194287757332]]\n",
            "\n",
            "Test set after feature scaling:\n",
            "[[0.0 1.0 0.0 -1.4661817944830124 -0.9069571034860727]\n",
            " [1.0 0.0 0.0 -0.44973664397484414 0.2056403393225306]]\n",
            "\n",
            "==================================================\n",
            "DATA PREPROCESSING COMPLETE!\n",
            "==================================================\n",
            "Final dataset shapes:\n",
            "X_train: (8, 5)\n",
            "X_test: (2, 5)\n",
            "y_train: (8,)\n",
            "y_test: (2,)\n",
            "\n",
            "The data is now ready for machine learning algorithms!\n"
          ]
        }
      ],
      "source": [
        "# Feature Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Create StandardScaler object\n",
        "sc = StandardScaler()\n",
        "\n",
        "# Fit and transform the training set\n",
        "X_train[:, 3:] = sc.fit_transform(X_train[:, 3:])\n",
        "\n",
        "# Transform the test set (only transform, don't fit)\n",
        "X_test[:, 3:] = sc.transform(X_test[:, 3:])\n",
        "\n",
        "print(\"Training set after feature scaling:\")\n",
        "print(X_train)\n",
        "print(\"\\nTest set after feature scaling:\")\n",
        "print(X_test)\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"DATA PREPROCESSING COMPLETE!\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Final dataset shapes:\")\n",
        "print(f\"X_train: {X_train.shape}\")\n",
        "print(f\"X_test: {X_test.shape}\")\n",
        "print(f\"y_train: {y_train.shape}\")\n",
        "print(f\"y_test: {y_test.shape}\")\n",
        "print(\"\\nThe data is now ready for machine learning algorithms!\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
