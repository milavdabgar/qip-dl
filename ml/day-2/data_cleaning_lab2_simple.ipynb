{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08184a8c",
   "metadata": {},
   "source": [
    "# Data Cleaning Exercise - Laboratory 2\n",
    "\n",
    "**AICTE Faculty ID:** 1-3241967546  \n",
    "**Faculty Name:** Milav Jayeshkumar Dabgar  \n",
    "**Date:** July 16, 2025\n",
    "\n",
    "---\n",
    "\n",
    "## Objective\n",
    "Perform data cleaning and preprocessing on the Car Evaluation dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b0e85f",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c012ec0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(\"Libraries imported!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a324c84f",
   "metadata": {},
   "source": [
    "## 2. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61949eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (1728, 7)\n",
      "\n",
      "First few rows:\n",
      "       0      1  2  3      4     5      6\n",
      "0  vhigh  vhigh  2  2  small   low  unacc\n",
      "1  vhigh  vhigh  2  2  small   med  unacc\n",
      "2  vhigh  vhigh  2  2  small  high  unacc\n",
      "3  vhigh  vhigh  2  2    med   low  unacc\n",
      "4  vhigh  vhigh  2  2    med   med  unacc\n"
     ]
    }
   ],
   "source": [
    "# Load car evaluation dataset\n",
    "data = pd.read_csv('/Users/milav/Code/qip-dl/ml/day-2/car_evaluation.csv', header=None)\n",
    "\n",
    "print(f\"Dataset shape: {data.shape}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b52729",
   "metadata": {},
   "source": [
    "## 3. Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a63f9a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset with column names:\n",
      "  buying  maint doors persons lug_boot safety  class\n",
      "0  vhigh  vhigh     2       2    small    low  unacc\n",
      "1  vhigh  vhigh     2       2    small    med  unacc\n",
      "2  vhigh  vhigh     2       2    small   high  unacc\n",
      "3  vhigh  vhigh     2       2      med    low  unacc\n",
      "4  vhigh  vhigh     2       2      med    med  unacc\n",
      "\n",
      "Rows: 1728, Columns: 7\n"
     ]
    }
   ],
   "source": [
    "# Add column names\n",
    "columns = ['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'class']\n",
    "data.columns = columns\n",
    "\n",
    "print(\"Dataset with column names:\")\n",
    "print(data.head())\n",
    "\n",
    "print(f\"\\nRows: {data.shape[0]}, Columns: {data.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21ec58cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "buying: ['vhigh' 'high' 'med' 'low']\n",
      "\n",
      "maint: ['vhigh' 'high' 'med' 'low']\n",
      "\n",
      "doors: ['2' '3' '4' '5more']\n",
      "\n",
      "persons: ['2' '4' 'more']\n",
      "\n",
      "lug_boot: ['small' 'med' 'big']\n",
      "\n",
      "safety: ['low' 'med' 'high']\n",
      "\n",
      "class: ['unacc' 'acc' 'vgood' 'good']\n"
     ]
    }
   ],
   "source": [
    "# Check categorical values in each column\n",
    "for col in data.columns:\n",
    "    print(f\"\\n{col}: {data[col].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834880b3",
   "metadata": {},
   "source": [
    "## 4. Check Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8efe870f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values:\n",
      "buying      0\n",
      "maint       0\n",
      "doors       0\n",
      "persons     0\n",
      "lug_boot    0\n",
      "safety      0\n",
      "class       0\n",
      "dtype: int64\n",
      "\n",
      "No missing values found!\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values:\")\n",
    "print(data.isnull().sum())\n",
    "\n",
    "if data.isnull().sum().sum() == 0:\n",
    "    print(\"\\nNo missing values found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbf8207",
   "metadata": {},
   "source": [
    "## 5. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d12e42c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After converting doors and persons:\n",
      "buying      object\n",
      "maint       object\n",
      "doors        int64\n",
      "persons      int64\n",
      "lug_boot    object\n",
      "safety      object\n",
      "class       object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Convert doors and persons to numeric\n",
    "processed_data = data.copy()\n",
    "\n",
    "# Convert doors\n",
    "door_mapping = {'2': 2, '3': 3, '4': 4, '5more': 5}\n",
    "processed_data['doors'] = processed_data['doors'].map(door_mapping)\n",
    "\n",
    "# Convert persons  \n",
    "person_mapping = {'2': 2, '4': 4, 'more': 6}\n",
    "processed_data['persons'] = processed_data['persons'].map(person_mapping)\n",
    "\n",
    "print(\"After converting doors and persons:\")\n",
    "print(processed_data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a62cda3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "buying encoded: [3 0 2 1]\n",
      "maint encoded: [3 0 2 1]\n",
      "lug_boot encoded: [2 1 0]\n",
      "safety encoded: [1 2 0]\n",
      "class encoded: [2 0 3 1]\n",
      "\n",
      "Encoded dataset:\n",
      "   buying  maint  doors  persons  lug_boot  safety  class\n",
      "0       3      3      2        2         2       1      2\n",
      "1       3      3      2        2         2       2      2\n",
      "2       3      3      2        2         2       0      2\n",
      "3       3      3      2        2         1       1      2\n",
      "4       3      3      2        2         1       2      2\n"
     ]
    }
   ],
   "source": [
    "# Encode categorical variables\n",
    "categorical_cols = ['buying', 'maint', 'lug_boot', 'safety', 'class']\n",
    "\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    processed_data[col] = le.fit_transform(processed_data[col])\n",
    "    print(f\"{col} encoded: {processed_data[col].unique()}\")\n",
    "\n",
    "print(\"\\nEncoded dataset:\")\n",
    "print(processed_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9773ae0",
   "metadata": {},
   "source": [
    "## 6. Separate Features and Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22e12b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (1728, 6)\n",
      "Target shape: (1728,)\n",
      "\n",
      "Feature columns: ['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety']\n",
      "Target classes: [2 0 3 1]\n"
     ]
    }
   ],
   "source": [
    "# Separate independent and dependent variables\n",
    "X = processed_data.drop('class', axis=1)\n",
    "y = processed_data['class']\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "\n",
    "print(\"\\nFeature columns:\", list(X.columns))\n",
    "print(\"Target classes:\", y.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3a629a",
   "metadata": {},
   "source": [
    "## 7. Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14769aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (1382, 6)\n",
      "Testing set: (346, 6)\n",
      "\n",
      "Data preprocessing completed!\n",
      "Dataset is ready for machine learning.\n"
     ]
    }
   ],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Testing set: {X_test.shape}\")\n",
    "\n",
    "print(\"\\nData preprocessing completed!\")\n",
    "print(\"Dataset is ready for machine learning.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f098ab5",
   "metadata": {},
   "source": [
    "## 8. Summary\n",
    "\n",
    "### **Data Cleaning Results:**\n",
    "\n",
    "Successfully processed the **Car Evaluation dataset** with the following characteristics:\n",
    "\n",
    "**Dataset Profile:**\n",
    "- **Size**: 1,728 samples × 7 features\n",
    "- **Data Quality**: No missing values detected\n",
    "- **Feature Types**: All categorical features requiring encoding\n",
    "\n",
    "**Key Transformations Applied:**\n",
    "\n",
    "1. **Column Naming**: Added meaningful names: `buying`, `maint`, `doors`, `persons`, `lug_boot`, `safety`, `class`\n",
    "\n",
    "2. **Categorical Analysis**: Identified distinct categories:\n",
    "   - `buying/maint`: 4 levels (vhigh, high, med, low)\n",
    "   - `doors`: 4 levels (2, 3, 4, 5more) \n",
    "   - `persons`: 3 levels (2, 4, more)\n",
    "   - `lug_boot`: 3 levels (small, med, big)\n",
    "   - `safety`: 3 levels (low, med, high)\n",
    "   - `class`: 4 levels (unacc, acc, vgood, good)\n",
    "\n",
    "3. **Numerical Conversion**: \n",
    "   - `doors`: Mapped to 2, 3, 4, 5\n",
    "   - `persons`: Mapped to 2, 4, 6\n",
    "\n",
    "4. **Label Encoding**: Converted categorical variables to numerical format for ML compatibility\n",
    "\n",
    "5. **Data Splitting**: \n",
    "   - Training: 1,382 samples (80%)\n",
    "   - Testing: 346 samples (20%)\n",
    "   - Stratified split maintains class distribution\n",
    "\n",
    "### **Final Dataset Status:**\n",
    "- **Features**: 6 numerical columns (buying, maint, doors, persons, lug_boot, safety)\n",
    "- **Target**: 1 categorical column (class) with 4 classes\n",
    "- **Ready for ML**: All preprocessing steps completed successfully\n",
    "\n",
    "### **Data Cleaning Pipeline Validated:**\n",
    "✅ **Load** → ✅ **Analyze** → ✅ **Clean** → ✅ **Transform** → ✅ **Split**\n",
    "\n",
    "The dataset is now properly formatted and ready for machine learning model training and evaluation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
